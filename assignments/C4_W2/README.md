# Text Summarization

- Accept [C4_W2](https://classroom.github.com/a/32OK8yRX)

---

## Lab

- Attention

  In this notebook you'll explore the three ways of attention (encoder-decoder attention, causal attention, and bi-directional self attention) and how to implement the latter two with dot product attention.
  
- The Transformer Decoder

  In this notebook you'll explore the transformer decoder and how to implement it with trax.s

- Positional encoding

  In this lab you will explore the positional encoding, which helps transformer to understand where in the sentence the individual words are located.

## Assignment

- Transformer Summarizer
